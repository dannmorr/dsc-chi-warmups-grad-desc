{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Warmup\n",
    "\n",
    "The gradients will continue until morale improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory questions\n",
    "\n",
    "#### 1) What is a loss function?\n",
    "1) A loss function is a function representing the error between the actual values of a target variable\n",
    "and the predictions made by a model\n",
    "\n",
    "A loss function can be used by a machine learning model to minimize error between predicted and target values\n",
    "\n",
    "Selection of a loss function often depends on both the specific model being used and the situation in which\n",
    "one is doing analysis\n",
    "\n",
    "\n",
    "\n",
    "#### 2) What is the loss function for SSE OLS regression?\n",
    "2) Loss function for OLS using SSE is mean square error, or loss = sum((y-f(x))**2)/n\n",
    "\n",
    "In practice, often calculated as sum((y-f(x))**2)/(2n), so that the exponent is cancelled out when taking the derivative\n",
    "and the calculations are a little easier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bad2cef840a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Write your answers here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "#Write your answers here\n",
    "SSE = (y-y_hat)**2\n",
    "SSE = (y - (b_0 + b_1*x))**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-f94717330e61>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-f94717330e61>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    (2*(y-y_hat)))*deriv inner function w regards to b_0 & b_1\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f(x) = y-y_hat\n",
    "g(x) = x**2\n",
    "\n",
    "SSE = g(f(x))\n",
    "\n",
    "(2*(y-y_hat)))* deriv inner function w regards to b_0 & b_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a loss function for a simple regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we'll import a series of 300 points from the data folder as an `X` feature, and another series of 300 points as a `y` target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data manip\n",
    "import numpy as np\n",
    "\n",
    "#make data\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#testing\n",
    "from test_scripts.test_class import Test\n",
    "\n",
    "#data import\n",
    "test = Test()\n",
    "X = test.load_ind('X')\n",
    "y = test.load_ind('y')\n",
    "\n",
    "#used for testing\n",
    "test = Test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the change in the loss function for a simple regression model, $y = \\beta  x + b$, as we step down the gradient once from an initial guess of 3 for $\\beta$ and 1 for $b$\n",
    "\n",
    "\n",
    "#### First, set up\n",
    "- define n as 300\n",
    "- define `beta` and `b` as initial guesses of 3 and 1, respectively\n",
    "- assign the loss function to `loss` using `y`, `X`, `n`, `beta` and `b`\n",
    "  - note: go ahead and multiply the denominator by 2 to cancel the partial derivative exponent step coming up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942.4909304580721"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 300\n",
    "b = 1\n",
    "beta = 3\n",
    "\n",
    "def loss(beta, b, n):\n",
    "    return sum((y-beta*X-b)**2)/(2*n)\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, calculate\n",
    "\n",
    "- determine the partial derivatives for `beta` and `b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-41.44519343763108, 5.399401084176953)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_deriv = sum((y-beta*X-b)*-X)/n\n",
    "b_deriv =sum((y-beta*X-b)*-1)/n\n",
    "\n",
    "\n",
    "beta_deriv, b_deriv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- re-define `beta` and `b` by \"stepping down the gradient\" - ie, subtract their respective partial derivatives from themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = beta-beta_deriv\n",
    "b = b - b_deriv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for beta:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "✅ **Hey, you did it.  Good job.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test for b:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "✅ **Hey, you did it.  Good job.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run this cell to test your work!\n",
    "\n",
    "print('test for beta:')\n",
    "test.run_test(beta, \"beta\")\n",
    "print()\n",
    "print('test for b:')\n",
    "test.run_test(b, \"b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- does `y = original_beta * X + original_b` have a smaller loss function value than `y = updated_beta * X + new_b`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942.4909304580721\n",
      "15.147998163619848\n"
     ]
    }
   ],
   "source": [
    "loss_original = loss(3, 1, 300)\n",
    "\n",
    "loss_current = loss(beta, b, 300)\n",
    "\n",
    "print(loss_original)\n",
    "print(loss_current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, do this 10 more times!\n",
    "\n",
    "- Put the machinery to calculate a new `beta` and `b` you've created inside of a function\n",
    "  - The function should take as inputs `beta`, `b`, `X`, and `y`\n",
    "  - (`X` and `y` should have default values)\n",
    "  - calculate the partial derivative of the loss function for `beta`\n",
    "  - calculate the partial derivative of the loss function for `b`\n",
    "  - subtract their respective partial derivatives from `beta` and `b`\n",
    "  - return updated `beta` and `b`\n",
    "\n",
    "\n",
    "- Put the function inside of a loop which runs 10 times\n",
    "\n",
    "- Calculate `beta` and `b`, starting with `beta`=3 and `b`=1, after 10 \"steps down the gradient\"\n",
    "\n",
    "- What does it look like the final `y = mx + b` equation should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta after 10 epochs: 48.34690547882362\n",
      "b after 10 epochs: 0.017270934505653077\n",
      "y = 48.34690547882362 * X + 0.017270934505653077, baby\n"
     ]
    }
   ],
   "source": [
    "#Your work here\n",
    "def calculate_descent(beta, b, X=X, y=y):\n",
    "    beta_deriv = sum((y-beta*X-b)*-X)/300\n",
    "    b_deriv = sum((y-beta*X-b)*-1)/300\n",
    "    \n",
    "    new_beta = beta - beta_deriv\n",
    "    new_b = b - b_deriv\n",
    "    \n",
    "    return {'beta':new_beta, 'b': new_b}\n",
    "\n",
    "beta = 3\n",
    "b = 1\n",
    "\n",
    "for epoch in range(0,10):\n",
    "    results = calculate_descent(beta, b)\n",
    "    beta = results['beta']\n",
    "    b = results['b']\n",
    "\n",
    "print(f'beta after 10 epochs: {beta}')\n",
    "print(f'b after 10 epochs: {b}')\n",
    "\n",
    "print(f'y = {beta} * X + {b}, baby')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test for beta:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "✅ **Hey, you did it.  Good job.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test for b:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "✅ **Hey, you did it.  Good job.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run this cell to test your work!\n",
    "\n",
    "print('test for beta:')\n",
    "test.run_test(beta, \"beta_10\")\n",
    "print()\n",
    "print('test for b:')\n",
    "test.run_test(b, \"b_10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Round\n",
    "\n",
    "Look at the loss function as we move from epoch to epoch\n",
    "\n",
    "Why do we not need a learning rate in this instance?\n",
    "\n",
    "Why might we need a learning rate in other instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your work here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
